{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Imports","metadata":{}},{"cell_type":"code","source":"import time\nimport gc\ngc.enable()\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nimport scipy.stats as st\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import #task-dependent\n\nfrom sklearn.ensemble import ExtraTreesClassifier as XTC\nfrom sklearn.ensemble import ExtraTreesRegressor as XTR\n\nimport optuna\nfrom optuna.samplers import TPESampler","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv('')\ntest = pd.read_csv('')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"SEED = 2311\n\nN_FOLDS = 5\nN_THREADS = 4 #number of CPUs\n\nIS_CLF = True #True for Classification, False for Regression\nTARGET = '----'\nID_COL = '----'\nTEST_INDEX = test.pop(ID_COL) # id column","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"features = list(test.columns)\ncat_features = list(test.select_dtypes('category').columns)\nnum_features = list(test.select_dtypes('number').columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[cat_features] = train[cat_features].astype('int')\ntest[cat_features] = test[cat_features].astype('int')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = LabelEncoder()\ntrain[TARGET] = labels.fit_transform(train[TARGET])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Baseline","metadata":{}},{"cell_type":"code","source":"baseline_params = {\n    'n_estimators': 150,\n    'n_jobs': N_THREADS,\n    'verbose': 0,\n    'random_state': SEED\n}\n\nif TASK_IS_CLF:\n    baseline = XTC(**baseline_params).fit(train[features], train[TARGET])\nelse:\n    baseline = XTR(**baseline_params).fit(train[features], train[TARGET])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions = baseline.predict(test[features])\n\nsubmission_baseline = pd.DataFrame({ID_COL: TEST_INDEX, \n                                    TARGET: labels.inverse_transform(predictions)})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"del baseline\ngc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Hyperparameter tuning","metadata":{}},{"cell_type":"code","source":"def objective(trial, train):\n    param_grid = {\n        'n_estimators': trial.suggest_int('n_estimators', 200, 2000, step=50),\n        'max_depth': trial.suggest_int('max_depth', 3, 15),\n        'max_features': trial.suggest_discrete_uniform('max_features', 0.1, 1.0, 0.1),\n        'bootstrap': trial.suggest_categorical('bootstrap', [True, False]),\n        'ccp_alpha': trial.suggest_uniform('ccp_alpha', 0.0, 0.1)\n    }\n    \n    if param_grid['bootstrap']:\n        param_grid['oob_score'] = trial.suggest_categorical('oob_score', [True, False])\n        param_grid['max_samples'] = trial.suggest_uniform('max_samples', 0.1, 1.0)\n    \n    if IS_CLF:\n        param_grid['criterion'] = trial.suggest_categorical('criterion', ['gini', 'entropy'])\n        param_grid['class_weight'] = trial.suggest_categorical('class_weight', ['balanced', 'balanced_subsample'])\n        model = XTC(**param_grid, verbose=0, n_jobs=N_THREADS, random_state=SEED)\n    else:\n        param_grid['criterion'] = trial.suggest_categorical('criterion', ['squared_error', 'absolute_error'])\n        model = XTR(**param_grid, verbose=0, n_jobs=N_THREADS, random_state=SEED)\n        \n    scores = []\n    for fold in range(N_FOLDS):\n        xtrain = train[train.fold != fold]\n        ytrain = xtrain[TARGET]\n        xval = train[train.fold == fold]\n        yval = xval[TARGET]\n        gc.collect()\n        \n        model.fit(xtrain[features], ytrain)\n        \n        val_preds = model.predict(xval[features])\n#         val_preds = model.predict_proba(xval[features])[:1]\n        score = ----(yval, val_preds)\n        scores.append(score)\n        \n    return np.mean(scores)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def tune(objective, direction, train):\n    study = optuna.create_study(sampler=TPESampler(seed=SEED),\n                                direction=direction)\n    \n    study.optimize(lambda trial: objective(trial, train),\n                   n_trials=100)\n    \n    best_params = study.best_params\n    print(f'Best score: {study.best_value:.5f}')\n    print('Best params:')\n    for key, value in best_params.items():\n        print(f'\\t{key}: {value}')\n    \n    return best_params","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"direction = '----' #maximize/minimize according to metric\nbest_params = tune(objective, direction, train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gc.collect()","metadata":{"_kg_hide-input":true,"_kg_hide-output":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# CV + Inference","metadata":{}},{"cell_type":"code","source":"def custom_cv(train, test, features, model):\n    oof_preds = {}\n    test_preds = []\n    scores = []\n    \n    cv_start = time.time()\n    for fold in range(N_SPLITS):\n        print('-' * 40)\n        \n        xtrain = train[train.fold != fold].reset_index(drop=True)\n        xval = train[train.fold == fold].reset_index(drop=True)    \n        val_idx = xval[ID_COL].values.tolist()\n        \n        fold_start = time.time()\n        \n        model.fit(xtrain[features], xtrain[TARGET])\n        val_preds = model.predict(xval[features])\n#         val_preds = model.predict_proba(xval[features])[:,1]\n        oof_preds.update(dict(zip(val_idx, val_preds)))\n        score = ----(xval[TARGET], val_preds)\n        scores.append(score)\n        \n        fold_end = time.time()\n        \n        print(f'Fold #{fold}: Score = {score:.5f}\\t[Time: {fold_end - fold_start:.2f} secs]')\n        \n        test_preds.append(model.predict(test[features]))\n#         test_preds.append(model.predict_proba(test[features])[:,1])\n        \n    cv_end = time.time()\n    print(f'\\nAverage score = {np.mean(scores):.5f} with std. dev. = {np.std(scores):.5f}')\n    print(f'[Total time: {cv_end - cv_start:.2f} secs]\\n')\n    \n    oof_preds = pd.DataFrame.from_dict(oof_preds, orient='index').reset_index()\n    test_preds = st.mode(np.column_stack(test_preds), axis=1).mode\n#     test_preds = np.mean(np.column_stack(test_preds), axis=1)\n    \n    return oof_preds, test_preds","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"if IS_CLF:\n    model = XTC(**best_params, verbose=0, n_jobs=N_THREADS, random_state=SEED)\nelse:\n    model = XTR(**best_params, verbose=0, n_jobs=N_THREADS, random_state=SEED)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_preds, test_preds = custom_cv(train, test, features, model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing and Submission","metadata":{}},{"cell_type":"code","source":"#any post-processing if needed\n\ntest_preds = labels.inverse_transform(test_preds)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission_xt = pd.DataFrame({ID_COL: TEST_INDEX, \n                              TARGET: test_preds})\n\nsubmission_xt.to_csv('submission_xt.csv', index=False)","metadata":{},"execution_count":null,"outputs":[]}]}